{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Exercise - Linear Regression Assumptions and Statistical Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "The problem at hand is to predict the housing prices of a town or a suburb based on the features of the locality provided to us. In the process, we need to identify the most important features in the dataset. We need to employ techniques of data preprocessing and build a linear regression model that predicts the prices for us. \n",
    "\n",
    "### Data Information\n",
    "\n",
    "Each record in the database describes a Boston suburb or town. The data was drawn from the Boston Standard Metropolitan Statistical Area (SMSA) in 1970. Detailed attribute information can be found below-\n",
    "\n",
    "Attribute Information (in order):\n",
    "- CRIM: per capita crime rate by town\n",
    "- ZN: proportion of residential land zoned for lots over 25,000 sq. ft.\n",
    "- INDUS: proportion of non-retail business acres per town\n",
    "- CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- NX: nitric oxides concentration (parts per 10 million)\n",
    "- RM: average number of rooms per dwelling\n",
    "- AGE: proportion of owner-occupied units built prior to 1940\n",
    "- DIS: weighted distances to five Boston employment centers\n",
    "- RAD: index of accessibility to radial highways\n",
    "- TAX: full-value property-tax rate per 10,000 dollars\n",
    "- PTRATIO: pupil-teacher ratio by town\n",
    "- LSTAT: %lower status of the population\n",
    "- MEDV: Median value of owner-occupied homes in 1000 dollars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the shape of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the info regarding column datatypes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get summary statistics for the numerical columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For the column `CHAS`, replace the 1 values with '*yes*' and 0 values with '*no*'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset\n",
    "\n",
    "Split the data into the dependent and independent variables, create dummy variables for the categorical variables, add a constant to the independent variables, and further split it in a ratio of 70:30 for train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make the linear model using statsmodels OLS and print the model summary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsFycww0v_cl"
   },
   "source": [
    "## Checking Linear Regression Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrn6suuxv_cl"
   },
   "source": [
    "**Check the following Linear Regression assumptions:**\n",
    "\n",
    "1. **No Multicollinearity**\n",
    "\n",
    "2. **Linearity of variables**\n",
    "\n",
    "3. **Independence of error terms**\n",
    "\n",
    "4. **Normality of error terms**\n",
    "\n",
    "5. **No Heteroscedasticity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSF5FtcYv_cl"
   },
   "source": [
    "### TEST FOR MULTICOLLINEARITY\n",
    "\n",
    "- Test for multicollinearity using VIF\n",
    "\n",
    "- **General Rule of thumb**:\n",
    "    - If VIF is 1 then there is no correlation between the $k$th predictor and the remaining predictor variables.\n",
    "    - If VIF exceeds 5 or is close to exceeding 5, we say there is moderate multicollinearity.\n",
    "    - If VIF is 10 or exceeding 10, it shows signs of high multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwXGio4fv_cl",
    "outputId": "a349add7-5d86-4bd8-ea9d-2f854064587b"
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# we will define a function to check VIF\n",
    "def checking_vif(predictors):\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"feature\"] = predictors.columns\n",
    "\n",
    "    # calculating VIF for each feature\n",
    "    vif[\"VIF\"] = [\n",
    "        variance_inflation_factor(predictors.values, i)\n",
    "        for i in range(len(predictors.columns))\n",
    "    ]\n",
    "    return vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3vNKNiVv_cl",
    "outputId": "462b548c-ae99-494f-868e-a5b7d624905c"
   },
   "outputs": [],
   "source": [
    "checking_vif(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSiS4SRaqH8q"
   },
   "source": [
    "### Removing Multicollinearity\n",
    "\n",
    "To remove multicollinearity\n",
    "\n",
    "1. Drop every column one by one that has a VIF score greater than 5.\n",
    "2. Look at the adjusted R-squared and RMSE of all these models.\n",
    "3. Drop the variable that makes the least change in adjusted R-squared.\n",
    "4. Check the VIF scores again.\n",
    "5. Continue till you get all VIF scores under 5.\n",
    "\n",
    "Let's define a function that will help us do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treating_multicollinearity(predictors, target, high_vif_columns):\n",
    "    \"\"\"\n",
    "    Checking the effect of dropping the columns showing high multicollinearity\n",
    "    on model performance (adj. R-squared and RMSE)\n",
    "\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    high_vif_columns: columns having high VIF\n",
    "    \"\"\"\n",
    "    # empty lists to store adj. R-squared and RMSE values\n",
    "    adj_r2 = []\n",
    "    rmse = []\n",
    "\n",
    "    # build ols models by dropping one of the high VIF columns at a time\n",
    "    # store the adjusted R-squared and RMSE in the lists defined previously\n",
    "    for cols in high_vif_columns:\n",
    "        # defining the new train set\n",
    "        train = predictors.loc[:, ~predictors.columns.str.startswith(cols)]\n",
    "\n",
    "        # create the model\n",
    "        olsmodel = sm.OLS(target, train).fit()\n",
    "\n",
    "        # adding adj. R-squared and RMSE to the lists\n",
    "        adj_r2.append(olsmodel.rsquared_adj)\n",
    "        rmse.append(np.sqrt(olsmodel.mse_resid))\n",
    "\n",
    "    # creating a dataframe for the results\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            \"col\": high_vif_columns,\n",
    "            \"Adj. R-squared after_dropping col\": adj_r2,\n",
    "            \"RMSE after dropping col\": rmse,\n",
    "        }\n",
    "    ).sort_values(by=\"Adj. R-squared after_dropping col\", ascending=False)\n",
    "    temp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of high VIF columns\n",
    "col_list = []\n",
    "\n",
    "res = treating_multicollinearity(___, y_train, col_list)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop = \"___\"\n",
    "___ = ___.loc[:, ~___.columns.str.startswith(col_to_drop)]\n",
    "___ = ___.loc[:, ~___.columns.str.startswith(col_to_drop)]\n",
    "\n",
    "# Check VIF now\n",
    "vif = checking_vif(___)\n",
    "print(\"VIF after dropping \", col_to_drop)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yN7Ojubv_cl"
   },
   "source": [
    "**Drop the high p-value variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bbkfXls6v_cl",
    "outputId": "506e626a-dc43-433a-cef8-d866a46f88b0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the model with the significant variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HhIm6bM0v_cl",
    "outputId": "71f575a3-7c62-43ae-c98b-c6642bcde213"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOMhV3y8v_cm"
   },
   "source": [
    "### TEST FOR LINEARITY AND INDEPENDENCE\n",
    "\n",
    "- Test for linearity and independence by making a plot of fitted values vs residuals and checking for patterns\n",
    "- If there is no pattern, then we say the model is linear and residuals are independent.\n",
    "- Otherwise, the model is showing signs of non-linearity and residuals are not independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "naX-iXItqH-b",
    "outputId": "96ccd571-f2c6-45b4-e52c-b756ae684432"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rM2_3rFov_cm"
   },
   "source": [
    "**Observations**\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qe2qzrSMv_cm"
   },
   "source": [
    "### TEST FOR NORMALITY\n",
    "\n",
    "- Test for normality by checking the distribution of residuals, by checking the Q-Q plot of residuals, and by using the Shapiro-Wilk test\n",
    "- If the residuals follow a normal distribution, they will make a straight line plot, otherwise not.\n",
    "- If the p-value of the Shapiro-Wilk test is greater than 0.05, we can say the residuals are normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NfQwPxjuv_cm",
    "outputId": "0665b7ad-be6e-4495-9138-001009f41c7e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INXt3nVlv_cm"
   },
   "source": [
    "**Observations**\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaBwB7t3v_cn"
   },
   "source": [
    "**Observations**\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSm3MU0Av_cn",
    "outputId": "a5ffcdbf-ba38-48b3-a2d9-bb025479fc35"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzcKbSZQv_cn"
   },
   "source": [
    "**Observations**\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUlVUV1Ov_cn"
   },
   "source": [
    "### TEST FOR HOMOSCEDASTICITY\n",
    "\n",
    "- Test for homoscedasticity by using the goldfeldquandt test\n",
    "- If we get a p-value greater than 0.05, we can say that the residuals are homoscedastic. Otherwise, they are heteroscedastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MKtbbgzQv_cn",
    "outputId": "49756fe8-7f7c-47eb-978c-626dffecb8f5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiwHjbE4v_cn"
   },
   "source": [
    "**Observations**\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRYSDgFZMKtm"
   },
   "source": [
    "### Final Model and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_Sqvs4TMKtn",
    "outputId": "a2e0c74b-7635-4238-f10a-618843f088a9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw inferences from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
